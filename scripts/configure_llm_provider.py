#!/usr/bin/env python3
"""
Configure LLM Provider for Sentinel Platform

This script allows easy switching between different LLM providers including:
- Mock (for benchmarking)
- Ollama (for local models)
- Anthropic, OpenAI, Google, etc. (for cloud providers)
"""

import os
import sys
import json
import requests
from typing import Optional, Dict

# Provider configurations
PROVIDER_CONFIGS = {
    "mock": {
        "SENTINEL_APP_LLM_PROVIDER": "mock",
        "SENTINEL_APP_LLM_MODEL": "mock-instant",
        "SENTINEL_APP_LLM_TEMPERATURE": "0.0",
        "SENTINEL_APP_LLM_MAX_TOKENS": "2000",
        "description": "Mock provider for instant benchmarking (no real LLM)"
    },
    "ollama-deepseek": {
        "SENTINEL_APP_LLM_PROVIDER": "ollama",
        "SENTINEL_APP_LLM_MODEL": "deepseek-coder:6.7b",
        "SENTINEL_APP_LLM_API_BASE": "http://localhost:11434",
        "SENTINEL_APP_LLM_TEMPERATURE": "0.5",
        "SENTINEL_APP_LLM_MAX_TOKENS": "4096",
        "description": "DeepSeek Coder 6.7B via Ollama (local)"
    },
    "ollama-codellama": {
        "SENTINEL_APP_LLM_PROVIDER": "ollama",
        "SENTINEL_APP_LLM_MODEL": "codellama:7b",
        "SENTINEL_APP_LLM_API_BASE": "http://localhost:11434",
        "SENTINEL_APP_LLM_TEMPERATURE": "0.5",
        "SENTINEL_APP_LLM_MAX_TOKENS": "4096",
        "description": "CodeLlama 7B via Ollama (local)"
    },
    "ollama-mistral": {
        "SENTINEL_APP_LLM_PROVIDER": "ollama",
        "SENTINEL_APP_LLM_MODEL": "mistral:7b",
        "SENTINEL_APP_LLM_API_BASE": "http://localhost:11434",
        "SENTINEL_APP_LLM_TEMPERATURE": "0.5",
        "SENTINEL_APP_LLM_MAX_TOKENS": "4096",
        "description": "Mistral 7B via Ollama (local)"
    },
    "anthropic": {
        "SENTINEL_APP_LLM_PROVIDER": "anthropic",
        "SENTINEL_APP_LLM_MODEL": "claude-sonnet-4-20250514",
        "SENTINEL_APP_LLM_TEMPERATURE": "0.5",
        "SENTINEL_APP_LLM_MAX_TOKENS": "2000",
        "description": "Anthropic Claude Sonnet 4 (API)"
    }
}

def check_ollama_status() -> bool:
    """Check if Ollama is running"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=2)
        return response.status_code == 200
    except:
        return False

def get_ollama_models() -> list:
    """Get list of available Ollama models"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=2)
        if response.status_code == 200:
            models = response.json().get("models", [])
            return [m.get("name", "") for m in models]
    except:
        pass
    return []

def update_env_file(config: Dict[str, str], env_file: str = ".env"):
    """Update .env file with new configuration"""
    
    # Read existing .env file
    existing_vars = {}
    if os.path.exists(env_file):
        with open(env_file, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    existing_vars[key] = value
    
    # Update with new config
    for key, value in config.items():
        if key != "description":
            existing_vars[key] = value
    
    # Write back
    with open(env_file, 'w') as f:
        f.write("# Sentinel Platform Configuration\n")
        f.write(f"# LLM Provider: {config.get('description', 'Unknown')}\n")
        f.write("# Generated by configure_llm_provider.py\n\n")
        
        # Write LLM settings first
        f.write("# LLM Configuration\n")
        for key in sorted(existing_vars.keys()):
            if key.startswith("SENTINEL_APP_LLM_"):
                f.write(f"{key}={existing_vars[key]}\n")
        
        f.write("\n# Other Settings\n")
        for key in sorted(existing_vars.keys()):
            if not key.startswith("SENTINEL_APP_LLM_"):
                f.write(f"{key}={existing_vars[key]}\n")
    
    print(f"‚úÖ Updated {env_file}")

def update_docker_compose_env():
    """Update docker-compose environment"""
    compose_file = "docker-compose.yml"
    if not os.path.exists(compose_file):
        compose_file = "../docker-compose.yml"
    
    if os.path.exists(compose_file):
        print(f"‚úÖ Docker compose file found at {compose_file}")
        print("   Run 'docker-compose restart orchestration_service' to apply changes")

def main():
    print("\n" + "="*60)
    print(" LLM Provider Configuration Tool ".center(60))
    print("="*60)
    
    # Check Ollama status
    ollama_running = check_ollama_status()
    if ollama_running:
        models = get_ollama_models()
        print(f"\n‚úÖ Ollama is running with {len(models)} models:")
        for model in models:
            print(f"   - {model}")
    else:
        print("\n‚ö†Ô∏è  Ollama is not running (local models unavailable)")
    
    # Show options
    print("\nAvailable configurations:")
    print("-"*60)
    options = []
    for i, (key, config) in enumerate(PROVIDER_CONFIGS.items(), 1):
        print(f"{i}. {key}: {config['description']}")
        options.append(key)
    
    # Get user choice
    print("\nSelect configuration (1-{}) or 'q' to quit: ".format(len(options)), end='')
    choice = input().strip()
    
    if choice.lower() == 'q':
        print("Cancelled")
        return
    
    try:
        idx = int(choice) - 1
        if 0 <= idx < len(options):
            selected = options[idx]
        else:
            print("Invalid choice")
            return
    except ValueError:
        if choice in options:
            selected = choice
        else:
            print("Invalid choice")
            return
    
    # Apply configuration
    config = PROVIDER_CONFIGS[selected]
    print(f"\nüìù Applying configuration: {selected}")
    print(f"   Provider: {config['SENTINEL_APP_LLM_PROVIDER']}")
    print(f"   Model: {config['SENTINEL_APP_LLM_MODEL']}")
    
    # Check if API key is needed
    provider = config['SENTINEL_APP_LLM_PROVIDER']
    if provider in ['anthropic', 'openai', 'google', 'mistral']:
        env_key = f"SENTINEL_APP_{provider.upper()}_API_KEY"
        if env_key not in os.environ:
            print(f"\n‚ö†Ô∏è  Warning: {env_key} not set in environment")
            print(f"   You'll need to set this for {provider} to work")
    
    # Update .env file
    update_env_file(config)
    
    # Update Docker environment
    update_docker_compose_env()
    
    print("\n‚úÖ Configuration complete!")
    print("\nTo apply changes:")
    print("1. For local testing: export $(cat .env | xargs)")
    print("2. For Docker: docker-compose restart orchestration_service")
    
    # If mock mode, offer to run benchmark
    if selected == "mock":
        print("\nüöÄ Mock provider configured for benchmarking!")
        print("   Run the benchmark script to test agent performance")

if __name__ == "__main__":
    main()